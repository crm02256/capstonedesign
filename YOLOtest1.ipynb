{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOT6UfuhmX/jl84dpQRNe2Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crm02256/capstonedesign/blob/master/YOLOtest1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1jSJ7L-weHa"
      },
      "source": [
        "!git clone https://github.com/pjreddie/darknet.git\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9Jij1P8w6eM"
      },
      "source": [
        "os.chdir(\"/content/darknet\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okTJAd0DxDle",
        "outputId": "b3182cb4-fe66-4f86-da35-24ac240fd2c0"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cfg\t  include\tLICENSE.gen   LICENSE.mit  python     src\n",
            "data\t  LICENSE\tLICENSE.gpl   LICENSE.v1   README.md\n",
            "examples  LICENSE.fuck\tLICENSE.meta  Makefile\t   scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzHnrZwFxuxs"
      },
      "source": [
        "!sed -i 's/GPU=0/GPU=1/g' Makefile \n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtPtNaG3xyWv"
      },
      "source": [
        "!wget http://pjreddie.com/media/files/yolo9000.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re0WStEO8Bg2"
      },
      "source": [
        "pre-trained models for different cfg-files can be downloaded from:\n",
        "yolo9000.cfg -> http://pjreddie.com/media/files/yolo9000.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdbDe3538UT0"
      },
      "source": [
        "How to use?\n",
        "Example of usage in cmd-files from \n",
        "\n",
        "```\n",
        "build\\darknet\\x64\\darknet_coco_9000.cmd\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1iocLEq817L",
        "outputId": "99509d2b-63f5-4ff8-fed3-6b10deb7c840"
      },
      "source": [
        "!./darknet yolo test cfg/yolo9000.cfg yolo9000.weights data/dog.jpg"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer     filters    size              input                output\n",
            "    0 conv     32  3 x 3 / 1   544 x 544 x   3   ->   544 x 544 x  32  0.511 BFLOPs\n",
            "    1 max          2 x 2 / 2   544 x 544 x  32   ->   272 x 272 x  32\n",
            "    2 conv     64  3 x 3 / 1   272 x 272 x  32   ->   272 x 272 x  64  2.727 BFLOPs\n",
            "    3 max          2 x 2 / 2   272 x 272 x  64   ->   136 x 136 x  64\n",
            "    4 conv    128  3 x 3 / 1   136 x 136 x  64   ->   136 x 136 x 128  2.727 BFLOPs\n",
            "    5 conv     64  1 x 1 / 1   136 x 136 x 128   ->   136 x 136 x  64  0.303 BFLOPs\n",
            "    6 conv    128  3 x 3 / 1   136 x 136 x  64   ->   136 x 136 x 128  2.727 BFLOPs\n",
            "    7 max          2 x 2 / 2   136 x 136 x 128   ->    68 x  68 x 128\n",
            "    8 conv    256  3 x 3 / 1    68 x  68 x 128   ->    68 x  68 x 256  2.727 BFLOPs\n",
            "    9 conv    128  1 x 1 / 1    68 x  68 x 256   ->    68 x  68 x 128  0.303 BFLOPs\n",
            "   10 conv    256  3 x 3 / 1    68 x  68 x 128   ->    68 x  68 x 256  2.727 BFLOPs\n",
            "   11 max          2 x 2 / 2    68 x  68 x 256   ->    34 x  34 x 256\n",
            "   12 conv    512  3 x 3 / 1    34 x  34 x 256   ->    34 x  34 x 512  2.727 BFLOPs\n",
            "   13 conv    256  1 x 1 / 1    34 x  34 x 512   ->    34 x  34 x 256  0.303 BFLOPs\n",
            "   14 conv    512  3 x 3 / 1    34 x  34 x 256   ->    34 x  34 x 512  2.727 BFLOPs\n",
            "   15 conv    256  1 x 1 / 1    34 x  34 x 512   ->    34 x  34 x 256  0.303 BFLOPs\n",
            "   16 conv    512  3 x 3 / 1    34 x  34 x 256   ->    34 x  34 x 512  2.727 BFLOPs\n",
            "   17 max          2 x 2 / 2    34 x  34 x 512   ->    17 x  17 x 512\n",
            "   18 conv   1024  3 x 3 / 1    17 x  17 x 512   ->    17 x  17 x1024  2.727 BFLOPs\n",
            "   19 conv    512  1 x 1 / 1    17 x  17 x1024   ->    17 x  17 x 512  0.303 BFLOPs\n",
            "   20 conv   1024  3 x 3 / 1    17 x  17 x 512   ->    17 x  17 x1024  2.727 BFLOPs\n",
            "   21 conv    512  1 x 1 / 1    17 x  17 x1024   ->    17 x  17 x 512  0.303 BFLOPs\n",
            "   22 conv   1024  3 x 3 / 1    17 x  17 x 512   ->    17 x  17 x1024  2.727 BFLOPs\n",
            "   23 conv  28269  1 x 1 / 1    17 x  17 x1024   ->    17 x  17 x28269  16.732 BFLOPs\n",
            "   24 detection\n",
            "mask_scale: Using default '1.000000'\n",
            "Loading weights from yolo9000.weights...Done!\n",
            "data/dog.jpg: Predicted in 0.402866 seconds.\n",
            "Not compiled with OpenCV, saving to predictions.png instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtMmD67rA_Bq"
      },
      "source": [
        "!./darknet yolo test /content/darknet/cfg/yolo9000.cfg yolo9000.weights /content/darknet/data/dog.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cz7YNrNEK48"
      },
      "source": [
        "!./darknet yolo test cfg/yolo9000.cfg yolov9000.weights data/dog.jpg -thresh 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "pDGcjmhe_O9Z",
        "outputId": "d1530c3a-d9f7-432d-9b37-9d453894d19b"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "fig, ax = plt.subplots()\n",
        "ax.tick_params(labelbottom=\"on\",bottom=\"on\")\n",
        "ax.tick_params(labelleft=\"on\",left=\"on\")\n",
        "ax.set_xticklabels([])\n",
        "ax.axis('off')\n",
        "file = '/content/darknet/predictions.jpg'\n",
        "if os.path.exists(file):\n",
        "  img = cv2.imread(file)\n",
        "  show_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  plt.imshow(show_img)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADKUlEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKgcV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIHQBcjcEy3+fc28AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY9LR0bWFjcv"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}